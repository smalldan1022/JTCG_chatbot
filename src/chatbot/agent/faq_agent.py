from dataclasses import dataclass, field
from typing import Literal

from agent_factory import AgentFactory, GenericAgentState
from langchain.chat_models import init_chat_model
from langchain_core.language_models.chat_models import BaseChatModel
from langchain_core.messages import HumanMessage, SystemMessage
from langgraph.checkpoint.base import BaseCheckpointSaver
from langgraph.checkpoint.memory import InMemorySaver
from langgraph.checkpoint.postgres import PostgresSaver
from langgraph.checkpoint.redis import RedisSaver
from langgraph.graph import END, StateGraph
from langgraph.prebuilt import ToolNode

from chatbot.tool.base_tool import ToolManager
from chatbot.tool.faq_tool import KnowledgeSearchTool, SimpleProductSearchTool
from chatbot.utils.load_env import get_openai_api_key
from chatbot.utils.vector_db import VecDBManager


@dataclass
class Config:
    checkpointer: str | None = "InMemory"  # e.g. "InMemory" | "SQLite" | "Postgres" | "Redis"
    model: str = "gpt-4o-mini"
    model_provider: str = "openai"
    temperature: float | None = 0
    max_token: int | None = 500
    db_uri: str | None = None  # for SQLite / Postgres
    redis_uri: str | None = None  # for Redis
    graph_invoke_config: dict | None = field(
        default_factory=lambda: {"configurable": {"thread_id": "1"}}
    )


class FAQAgent(AgentFactory):
    def __init__(self):
        super().__init__()
        self.config = Config()
        self.api_key = get_openai_api_key()
        self.vec_db_manager = VecDBManager(api_key=self.api_key)
        self.tool_manager = ToolManager()
        self._setup_tools()
        self.model = self.get_llm()
        self.checkpointer = self.get_checkpointer()

    def _setup_tools(self):
        self.tool_manager.register_tool(SimpleProductSearchTool())
        self.tool_manager.register_tool(KnowledgeSearchTool(self.vec_db_manager))

        print(f"ğŸ”§ Total registered tool number: {len(self.tool_manager.tools)}.")

    def get_checkpointer(self) -> BaseCheckpointSaver:
        match self.config.checkpointer:
            case "InMemory":
                return InMemorySaver()
            case "Postgres":
                return PostgresSaver.from_conn_string(url=self.config.db_uri)
            case "Redis":
                return RedisSaver.from_conn_string(url=self.config.redis_uri)
            case _:
                raise ValueError(f"Unsupported checkpointer type: {self.config.checkpointer}")

    def get_llm(self) -> BaseChatModel:
        tools = self.tool_manager.get_langchain_tools()
        return init_chat_model(
            model=self.config.model,
            model_provider=self.config.model_provider,
            api_key=self.api_key,
            temperature=self.config.temperature,
            max_tokens=self.config.max_token,
        ).bind_tools(tools)

    def extract_user_info(self, state: GenericAgentState):
        """This is just a simple user information extraction"""
        user_info = state.get("user_info", {})

        for message in state["messages"]:
            if isinstance(message, HumanMessage):
                content = message.content.lower()
                if "my name is" in content or "i'm" in content:
                    # Get the user name
                    words = content.split()
                    for i, word in enumerate(words):
                        if word in ["i'm", "name", "is"] and i + 1 < len(words):
                            name = words[i + 1].strip(",.!")
                            if name.isalpha():
                                user_info["name"] = name

                if "live in" in content or "from" in content:
                    # Get the location
                    if "live in" in content:
                        location = content.split("live in")[-1].strip(",.!")
                    elif "from" in content:
                        location = content.split("from")[-1].strip(",.!")
                    user_info["location"] = location.strip()

        print(f"ğŸ“ UPDATED USER INFO: {user_info}")
        return {"user_info": user_info}

    def agent_node(self, state: GenericAgentState) -> GenericAgentState:
        """Main agent reasoning node"""
        print("ğŸ¤– AGENT THINKING...")

        user_info = state.get("user_info", {})
        user_context = ""
        if user_info:
            name = user_info.get("name", "")
            location = user_info.get("location", "")
            if name or location:
                user_context = f"\nç”¨æˆ¶è³‡è¨Š: å§“å: {name}, åœ°é»: {location}"

        tool_descriptions = self.tool_manager.get_tool_descriptions()

        system_msg = SystemMessage(
            content=f"""
        ä½ æ˜¯ä¸€å€‹å“ç‰Œæ™ºèƒ½åŠ©ç†ã€‚
        - å“ç‰Œä»‹ç´¹ï¼š**JTCG Shop** å°ˆæ³¨æ–¼å·¥ä½œç©ºé–“é«”é©—èˆ‡å‘¨é‚Šé…ä»¶çš„é¸å“èˆ‡è¨­è¨ˆï¼ŒåŒ…å«è¢å¹•è‡‚ã€å£æ›æ”¯æ¶ã€èµ°ç·šæ”¶ç´èˆ‡å®‰è£é…ä»¶ç­‰ã€‚æˆ‘å€‘ç›¸ä¿¡ã€Œå¥½ç”¨çš„æ¡Œé¢ï¼Œèƒ½è®“å°ˆæ³¨æ›´é•·ã€éˆæ„Ÿæ›´è¿‘ã€ã€‚å› æ­¤å¾ **ç›¸å®¹æ€§**ï¼ˆVESA/æ‰¿é‡/æ¡Œæ¿æ¢ä»¶ï¼‰ã€**è€ç”¨åº¦**ï¼ˆæè³ª/çµæ§‹ï¼‰ã€åˆ° **å®‰è£å‹å–„**ï¼ˆå®Œæ•´é…ä»¶èˆ‡æ¸…æ¥šæŒ‡å—ï¼‰ï¼Œæ¯ä¸€é …ç”¢å“éƒ½ä»¥å¯¦éš›ä½¿ç”¨æƒ…å¢ƒç‚ºä¸­å¿ƒè¨­è¨ˆèˆ‡ç¯©é¸ã€‚JTCG Shop ä»¥å¿«é€Ÿå‡ºè²¨ã€é€æ˜æ”¿ç­–èˆ‡è²¼å¿ƒå®¢æœç‚ºæ ¸å¿ƒï¼Œæä¾›å¾**é¸è³¼å»ºè­° â†’ å®‰è£æŒ‡å¼• â†’ å”®å¾Œç¶­è­·**çš„ä¸€æ¢é¾æ”¯æ´ï¼Œè®“æ¯ä½ä½¿ç”¨è€…éƒ½èƒ½æ­é…å‡ºæœ€é †æ‰‹ã€æœ€èˆ’é©çš„å·¥ä½œç’°å¢ƒã€‚
        - **å“ç‰Œä¸»å¼µ**ï¼šBetter Desk, Better Focus.
        - **æ ¸å¿ƒç‰¹è‰²**ï¼šç›¸å®¹æ€§æ¸…æ¥šã€å®‰è£ä¸è¸©é›·ã€å”®å¾Œå¥½æºé€šã€‚
        - **è§’è‰²å£å»**ï¼šå°ˆæ¥­ã€å¯ä¿¡ã€å‹å–„ï¼›å…ˆç›´ç­”ã€å†è£œå……ï¼›é¿å…å†—é•·ã€‚
        - **èªç³»ä¸€è‡´**ï¼šå›è¦†èªç³»**ç«‹å³è·Ÿéš¨ä½¿ç”¨è€…æœ€æ–°è¨Šæ¯**ï¼›ä¸­æ–‡è‡ªå‹•å¥—ç”¨ç¹/ç°¡é«”ä¸€è‡´ï¼›å¼•ç”¨ FAQ æ™‚åŒæ­¥è½‰æˆä½¿ç”¨è€…èªè¨€è®Šé«”ã€‚
        - **å¼•ç”¨é€æ˜**ï¼šæœ‰ä¾†æºå°±**æ˜ç¢ºé™„ä¸Šé€£çµ**ï¼›åœ–ç‰‡åªä½¿ç”¨**å·¥å…·è¿”å›**çš„åœ–é€£çµã€‚
        - **ä¸è‡†æ¸¬**ï¼šæ²’æœ‰æ¬Šå¨è³‡æ–™å°±èªªæ˜ã€Œç›®å‰ç„¡æ³•ç¢ºèªã€ï¼Œä¸¦æä¾›å¯è¡Œä¸‹ä¸€æ­¥ï¼ˆä¾‹å¦‚çœŸäººå”åŠ©ï¼‰ã€‚

        ä½¿ç”¨è€…è³‡è¨Š:
        {user_context}

        å¯ç”¨å·¥å…·:
        {tool_descriptions}

        ä½¿ç”¨åŸå‰‡:
        1.å„ªå…ˆä½¿ç”¨çŸ¥è­˜åº«æŸ¥è©¢ï¼Œå°æ–¼çŸ¥è­˜åº«æŸ¥è©¢ï¼Œä½¿ç”¨ knowledge_search å·¥å…·ï¼Œå›è¦†æ™‚æä¾›å¯è¿½æº¯ä¾†æºé€£çµèˆ‡ï¼ˆå¦‚æœ‰ï¼‰ç›¸é—œåœ–ç‰‡ã€‚
        2.å¦‚æœåœ¨çŸ¥è­˜åº«æ‰¾ä¸åˆ°ç›¸é—œè³‡è¨Šï¼Œæ›´æ”¹ç‚ºä½¿ç”¨ product_search å·¥å…·å›ç­”ç”¢å“ç›¸é—œå•é¡Œ
        3.æ ¹æ“šç”¨æˆ¶å•é¡Œé¸æ“‡æœ€åˆé©çš„å·¥å…·

        è«‹ä»”ç´°æ€è€ƒä¸¦é¸æ“‡åˆé©çš„å·¥å…·ä¾†å›ç­”ç”¨æˆ¶å•é¡Œã€‚
        """
        )
        messages = [system_msg] + state["messages"]
        response = self.model.invoke(messages)

        print(f"ğŸ’­ AGENT RESPONSE: {response.content}")
        if response.tool_calls:
            print(f"ğŸ› ï¸  TOOLS TO CALL: {[tc['name'] for tc in response.tool_calls]}")

        return {
            "messages": [response],
            "user_info": state.get("user_info", {}),
        }

    def should_continue(self, state: GenericAgentState) -> Literal["tools", "end"]:
        if not state["messages"]:
            return "end"

        last_message = state["messages"][-1]

        if hasattr(last_message, "tool_calls") and last_message.tool_calls:
            print("â¡ï¸  ç¹¼çºŒåŸ·è¡Œå·¥å…·")
            return "tools"

        print("âœ… çµæŸå°è©±")
        return "end"

    def create_agent_graph(self) -> StateGraph:
        graph = StateGraph(GenericAgentState)

        graph.add_node("extract_user_info", self.extract_user_info)
        graph.add_node("agent", self.agent_node)
        graph.add_node("tools", ToolNode(self.tool_manager.get_langchain_tools()))

        graph.set_entry_point("extract_user_info")
        graph.add_edge("extract_user_info", "agent")
        graph.add_conditional_edges("agent", self.should_continue, {"tools": "tools", "end": END})
        graph.add_edge("tools", "agent")

        return graph.compile(checkpointer=self.checkpointer)


if __name__ == "__main__":
    agent = FAQAgent()
    user_inputs = [
        "æˆ‘å« Dan, æˆ‘æœ‰é€€è²¨ç›¸é—œå•é¡Œæƒ³æŸ¥è©¢",
        "è«‹å‘Šè¨´æˆ‘å¦‚ä½•é€€è²¨",
    ]
    agent.run_conversation(user_inputs=user_inputs)
