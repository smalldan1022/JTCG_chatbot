from langchain.agents import AgentType, Tool, initialize_agent
from langchain.callbacks.base import BaseCallbackHandler
from langchain.chat_models import init_chat_model
from langchain.memory import ConversationBufferMemory
from langchain_tavily import TavilySearch
from utils.load_env import get_openai_api_key, get_tavily_api_key


# -----------------------------
# è‡ªå®šç¾© Callback ä¾†æ•æ‰æ‰€æœ‰æ­¥é©Ÿ
# -----------------------------
class DetailedCallbackHandler(BaseCallbackHandler):
    def __init__(self):
        self.step_count = 0

    def on_agent_action(self, action, **kwargs):
        self.step_count += 1
        print(f"\nğŸ”§ STEP {self.step_count}: ACTION")
        print(f"Tool: {action.tool}")
        print(f"Input: {action.tool_input}")
        print(f"Reasoning: {action.log}")
        print("-" * 50)

    def on_tool_start(self, serialized, input_str, **kwargs):
        print(f"ğŸ› ï¸  TOOL EXECUTION: {serialized.get('name', 'Unknown')}")
        print(f"Input: {input_str}")

    def on_tool_end(self, output, **kwargs):
        print("ğŸ“¤ TOOL RESULT:")
        print(f"Output: {output}")
        print("-" * 50)

    def on_agent_finish(self, finish, **kwargs):
        print("âœ… FINAL ANSWER:")
        print(f"Output: {finish.return_values}")
        print("=" * 60)


# -----------------------------
# 1ï¸âƒ£ å–å¾— API key
# -----------------------------
api_key = get_openai_api_key()
tavily_api_key = get_tavily_api_key()

# -----------------------------
# 2ï¸âƒ£ åˆå§‹åŒ–æ¨¡å‹
# -----------------------------
model = init_chat_model(
    model="gpt-4o-mini", model_provider="openai", api_key=api_key, temperature=0, max_tokens=1000
)

# -----------------------------
# 3ï¸âƒ£ åˆå§‹åŒ–å·¥å…·
# -----------------------------
search_tool = TavilySearch(api_key=tavily_api_key, max_results=3)

tools = [
    Tool(
        name="Search",
        func=search_tool.run,
        description="Use this tool to search the web for current information. Input should be a search query.",
    )
]

# -----------------------------
# 4ï¸âƒ£ åˆå§‹åŒ–è¨˜æ†¶é«”
# -----------------------------
memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)

# -----------------------------
# 5ï¸âƒ£ å»ºç«‹ AgentExecutorï¼ˆä½¿ç”¨ callbackï¼‰
# -----------------------------
callback_handler = DetailedCallbackHandler()

agent_executor = initialize_agent(
    tools=tools,
    llm=model,
    agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION,
    memory=memory,
    max_iterations=5,
    handle_parsing_errors=True,
    verbose=True,  # å•Ÿç”¨å…§å»ºçš„ verbose
    callbacks=[callback_handler],  # æ·»åŠ è‡ªå®šç¾© callback
)

# -----------------------------
# 6ï¸âƒ£ ç³»çµ± prompt
# -----------------------------
system_message = """You are a helpful assistant. 
When you need current information, use the search tool.
Think step by step and show your reasoning process clearly."""

# -----------------------------
# 7ï¸âƒ£ å¤šè¼ªå°è©±ç¤ºä¾‹
# -----------------------------
inputs = [
    "Hi, I'm Bob and I live in SF.",
    "What's my name and where do I live?",
    "What's the current weather in the place I am living?",
]

for i, user_input in enumerate(inputs, 1):
    print(f"\n{'=' * 60}")
    print(f"CONVERSATION ROUND {i}")
    print(f"{'=' * 60}")
    print(f"ğŸ‘¤ USER: {user_input}")
    print(f"{'=' * 60}")

    # é‡ç½®æ­¥é©Ÿè¨ˆæ•¸å™¨
    callback_handler.step_count = 0

    try:
        # åŸ·è¡Œå°è©±
        result = agent_executor.run(input=f"{system_message}\n\nUser: {user_input}")

        print("\nğŸ¤– FINAL RESPONSE:")
        print(f"{result}")

    except Exception as e:
        print(f"âŒ ERROR: {e}")

    print("\nğŸ“ CURRENT MEMORY:")
    print(f"Chat History: {memory.chat_memory.messages}")
    print("\n" + "=" * 80 + "\n")

# -----------------------------
# 8ï¸âƒ£ é¡å¤–ï¼šé¡¯ç¤ºå®Œæ•´è¨˜æ†¶é«”å…§å®¹
# -----------------------------
print("ğŸ§  COMPLETE CONVERSATION MEMORY:")
for i, message in enumerate(memory.chat_memory.messages):
    print(f"{i + 1}. {message.__class__.__name__}: {message.content}")
